{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as netx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(my_file):\n",
    "    file = open(my_file, \"r\")\n",
    "    data = file.readlines()\n",
    "    text_blob = data[0].split(\". \")\n",
    "    sentences = []\n",
    "    for sentences in text_blob:\n",
    "        sentences.append(sentence.replace(\"[^a-za-Z]\", \" \").split(\" \"))\n",
    "        sentences.pop()\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (900162111.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/c4/glpjh9156n3gscn_9h4r_d1h0000gn/T/ipykernel_89435/900162111.py\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    elif vector1[all_words.index(w)] += 1\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def sentence_similarity_track(sen1, sen2, stopwords = None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "        \n",
    "    #makes all words in sentences 1 and 2 lowercase and puts into array\n",
    "    sen1 = [word.lower() for word in sen1]\n",
    "    sen2 = [word.lower() for word in sen2]\n",
    "    \n",
    "    #combines all sentence 1 and 2\n",
    "    full_text_words = list(set(sen1+sen2))\n",
    "    \n",
    "    \n",
    "    #add proper commentary/documentation\n",
    "    vector1 = [0] *len(full_text_words)\n",
    "    vector2 = [0] *len(full_text_words)\n",
    "    for words in sen1:\n",
    "        if words in stopwords:\n",
    "            continue\n",
    "        elif vector1[full_text_words.index(w)] += 1\n",
    "    for words in sen2:\n",
    "        if words in stopwords:\n",
    "            continue\n",
    "        elif vector2[full_text_words.index(w)] += 1\n",
    "        \n",
    "    #checks the similarity between the 2 sentences\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(sentences, stop_words):\n",
    "    similarity_mat = np.zeroes(len(sentences), len(sentences))\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2:\n",
    "                continue\n",
    "            similarity_mat[idx1][idx2] = sentence_similarity_track(sentences[idx1], sentences[idx2], stop_words)\n",
    "    \n",
    "    return similarity_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary(my_file, top_n = 5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summary = []\n",
    "    sentences = read_text(my_file)\n",
    "    sentence_sim_matrix = similarity_matrix(sentences, stop_words)\n",
    "    sentence_sim_graph = nx.from_numpy_array(sentences)\n",
    "    scoring = nx.pagerank(sentence_sim_graph)\n",
    "    ranked_entences = sorted(((scoring[i],s) for i, s in enumerate(sentences)), reverse = true)\n",
    "    for i in range(top_n):\n",
    "        summary.append(\" \".join(ranked_entences[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only join an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/glpjh9156n3gscn_9h4r_d1h0000gn/T/ipykernel_89435/3356989062.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Summary: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\". \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only join an iterable"
     ]
    }
   ],
   "source": [
    "print(\"Summary: \\n\", \". \".join(show_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
