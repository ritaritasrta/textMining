{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9386f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from parrot import Parrot\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd009ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reproducability\n",
    "def random_state(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "random_state(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7538092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\", use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a33e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Hey this is Rita and welcome to my text mining project. This txt file will be used as an input feeder. I'm just going to type a bunch of stuff here and feed it into the main program that is called text_summarizer. I watched a bunch of YouTube videos and tried to copy different methods and pieced together different variations on how to efficiently write a summarizer program. Feel free to scour the code and download it to run your text file through. It can really help you with summarizing textbooks, books, phamphlets, etc. Enjoy!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43350c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_main_file(x):\n",
    "    with open('textMiningExample.txt', 'r') as file:\n",
    "        lines = file.readline()\n",
    "        return lines\n",
    "    #doesnt need debugging works perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cba6ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes existing text, tokenizes, and splits tokenized list into different lines\n",
    "def split_to_sent(x):\n",
    "    for lines in file:\n",
    "        lines = lines.lower()\n",
    "        lines = sent_tokenize(lines)\n",
    "        for element in lines:\n",
    "            return element\n",
    "#DEBUGGING NOTE: will only print first line...why? FIX \n",
    "#update: error says I try to open a closed file????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39bf0a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEY this is Rita  and welcome to my text mining project. This txt file will be used as an input feeder. I'm just going to type a bunch of stuff here and feed it into the main program that is called text_summarizer. I watched a bunch of YouTube videos and tried to copy different methods and pieced together different variations on how to efficiently write a summarizer program. Feel free to scour the code and download it to run your text file through. It can really help you with summarizing textbooks, books, phamphlets, etc. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "#Remove all non-ascii characters\n",
    "def remove_non_ascii(lines):\n",
    "    lines = lines.encode('ascii', 'ignore')\n",
    "    lines = lines.decode('ascii')\n",
    "    return lines\n",
    "print(remove_non_ascii(lines))\n",
    "#SUCCESSSSSS!!!!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd5ba59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(x):\n",
    "    #get all english stop words from nltk\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "#remove all stop words in english and place relevent text into new file called cleanFile.txt\n",
    "    words = lines.split() \n",
    "    for element in words: \n",
    "        if not element in stop_words: \n",
    "            appendFile = open('cleanFile.txt','a') \n",
    "            appendFile.write(\" \"+element) \n",
    "            appendFile.close()\n",
    "\n",
    "\n",
    "with open('cleanFile.txt', 'r') as newfile:\n",
    "        lines = newfile.readline()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21748957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey Rita welcome text mining project. This txt file used input feeder. I'm going type bunch stuff feed main program called text_summarizer. I watched bunch YouTube videos tried copy different methods pieced together different variations efficiently write summarizer program. Feel free scour code download run text file through. It really help summarizing textbooks, books, phamphlets, etc. Enjoy! HEY Rita welcome text mining project. This txt file used input feeder. I'm going type bunch stuff feed main program called text_summarizer. I watched bunch YouTube videos tried copy different methods pieced together different variations efficiently write summarizer program. Feel free scour code download run text file through. It really help summarizing textbooks, books, phamphlets, etc. Enjoy! HEY Rita welcome text mining project. This txt file used input feeder. I'm going type bunch stuff feed main program called text_summarizer. I watched bunch YouTube videos tried copy different methods pieced together different variations efficiently write summarizer program. Feel free scour code download run text file through. It really help summarizing textbooks, books, phamphlets, etc. Enjoy! HEY Rita ðŸ—£ welcome text mining project. This txt file used input feeder. I'm going type bunch stuff feed main program called text_summarizer. I watched bunch YouTube videos tried copy different methods pieced together different variations efficiently write summarizer program. Feel free scour code download run text file through. It really help summarizing textbooks, books, phamphlets, etc. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "def copy_to_other_file():\n",
    "    with open('cleanFile.txt', 'r') as cleanFile:\n",
    "        secLines = cleanFile.readline()\n",
    "        return secLines\n",
    "        #print(secLines)\n",
    "    #DEBUGGING NOTE: why is it looping so many times???\n",
    "print(copy_to_other_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb2bc750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "open_main_file(file)\n",
    "#split_to_sent(file)\n",
    "remove_non_ascii(lines)\n",
    "insert_to_clean_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ef790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
