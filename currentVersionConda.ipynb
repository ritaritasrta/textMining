{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9386f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from parrot import Parrot\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1b64c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reproducability\n",
    "def random_state(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "random_state(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56d33c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\", use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a33e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Hey this is Rita and welcome to my text mining project. This txt file will be used as an input feeder. I'm just going to type a bunch of stuff here and feed it into the main program that is called text_summarizer. I watched a bunch of YouTube videos and tried to copy different methods and pieced together different variations on how to efficiently write a summarizer program. Feel free to scour the code and download it to run your text file through. It can really help you with summarizing textbooks, books, phamphlets, etc. Enjoy!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43350c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_main_file(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readline()\n",
    "        return lines\n",
    "    #doesnt need debugging works perfectly\n",
    "\n",
    "#file_content = open_main_file('textMiningExample.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "39bf0a4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c4/glpjh9156n3gscn_9h4r_d1h0000gn/T/ipykernel_77985/1181344853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_non_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#debug decode func not working\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c4/glpjh9156n3gscn_9h4r_d1h0000gn/T/ipykernel_77985/1181344853.py\u001b[0m in \u001b[0;36mremove_non_ascii\u001b[0;34m(file_content)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mword_at_hand_from_file\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword_at_hand_from_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "#Remove all non-ascii characters\n",
    "def remove_non_ascii(file_content):\n",
    "    word_at_hand_from_file = \"\"\n",
    "    for word in file_content:\n",
    "        replace = word.encode('ascii', 'ignore')\n",
    "        replace = word.decode('ascii')\n",
    "        word_at_hand_from_file += replace + \" \"\n",
    "    return word_at_hand_from_file\n",
    "    \n",
    "\n",
    "print(remove_non_ascii(file_content))\n",
    "#debug decode func not working\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd5ba59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(word):\n",
    "    #get all english stop words from nltk\n",
    "    text_tokens = word.split()\n",
    "    stop_words = stopwords.words('english')\n",
    "    #print(stop_words)\n",
    "\n",
    "    #remove all stop words in english and place relevent text into new file called cleanFile.txt\n",
    "    output = \"\" \n",
    "    for word in text_tokens: \n",
    "        if not (word in stop_words): \n",
    "            output += word + \" \"\n",
    "    return output\n",
    "\n",
    "\n",
    "#print(\" \".join(file_content))\n",
    "#print()\n",
    "#print(remove_stop_words(\" \".join(file_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb2bc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content = open_main_file('textMiningExample.txt')\n",
    "file_content = file_content.lower()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
