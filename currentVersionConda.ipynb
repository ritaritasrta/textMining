{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9386f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a33e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Hey this is Rita and welcome to my text mining project. This txt file will be used as an input feeder. I'm just going to type a bunch of stuff here and feed it into the main program that is called text_summarizer. I watched a bunch of YouTube videos and tried to copy different methods and pieced together different variations on how to efficiently write a summarizer program. Feel free to scour the code and download it to run your text file through. It can really help you with summarizing textbooks, books, phamphlets, etc. Enjoy!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43350c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('textMiningExample.txt', 'r') as file:\n",
    "    lines = file.readline()\n",
    "    #code above is just to check\n",
    "    #print(lines) #used to test if file opens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cba6ee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey this is rita ðŸ—£ and welcome to my text mining project.\n"
     ]
    }
   ],
   "source": [
    "#takes existing text, tokenizes, and splits tokenized list into different lines\n",
    "def split_to_sent(lines):\n",
    "    lines = lines.lower()\n",
    "    lines = sent_tokenize(lines)\n",
    "    #print(*lines,sep='\\n')\n",
    "    for element in lines:\n",
    "        return element\n",
    "    \n",
    "print(split_to_sent(lines))\n",
    "#DEBUGGING NOTE: will only print first line...why? FIX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "39bf0a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEY this is Rita  and welcome to my text mining project. This txt file will be used as an input feeder. I'm just going to type a bunch of stuff here and feed it into the main program that is called text_summarizer. I watched a bunch of YouTube videos and tried to copy different methods and pieced together different variations on how to efficiently write a summarizer program. Feel free to scour the code and download it to run your text file through. It can really help you with summarizing textbooks, books, phamphlets, etc. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "#Remove all non-ascii characters\n",
    "def remove_non_ascii(lines):\n",
    "    lines = lines.encode('ascii', 'ignore')\n",
    "    lines = lines.decode('ascii')\n",
    "    return lines\n",
    "print(remove_non_ascii(lines))\n",
    "#SUCCESSSSSS!!!!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd5ba59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_clean_file():\n",
    "    #get all english stop words from nltk\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "#remove all stop words in english and place relevent text into new file called cleanFile.txt\n",
    "words = lines.split() \n",
    "for element in words: \n",
    "    if not element in stop_words: \n",
    "        appendFile = open('cleanFile.txt','a') \n",
    "        appendFile.write(\" \"+element) \n",
    "        appendFile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21748957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey Rita welcome text mining project. This txt file used input feeder. I'm going type bunch stuff feed main program called text_summarizer. I watched bunch YouTube videos tried copy different methods pieced together different variations efficiently write summarizer program. Feel free scour code download run text file through. It really help summarizing textbooks, books, phamphlets, etc. Enjoy! HEY Rita welcome text mining project. This txt file used input feeder. I'm going type bunch stuff feed main program called text_summarizer. I watched bunch YouTube videos tried copy different methods pieced together different variations efficiently write summarizer program. Feel free scour code download run text file through. It really help summarizing textbooks, books, phamphlets, etc. Enjoy! HEY Rita welcome text mining project. This txt file used input feeder. I'm going type bunch stuff feed main program called text_summarizer. I watched bunch YouTube videos tried copy different methods pieced together different variations efficiently write summarizer program. Feel free scour code download run text file through. It really help summarizing textbooks, books, phamphlets, etc. Enjoy! HEY Rita ðŸ—£ welcome text mining project. This txt file used input feeder. I'm going type bunch stuff feed main program called text_summarizer. I watched bunch YouTube videos tried copy different methods pieced together different variations efficiently write summarizer program. Feel free scour code download run text file through. It really help summarizing textbooks, books, phamphlets, etc. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "with open('cleanFile.txt', 'r') as cleanFile:\n",
    "    secLines = cleanFile.readline()\n",
    "    print(secLines)\n",
    "    #DEBUGGING NOTE: why is it looping so many times???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bc750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
